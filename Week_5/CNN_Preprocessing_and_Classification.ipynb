{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52779f57",
   "metadata": {},
   "source": [
    "# üß† Complete Image Preprocessing and Multi-Class Classification using CNN (Keras + CIFAR-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00522cf7",
   "metadata": {},
   "source": [
    "This notebook demonstrates a complete pipeline for image preprocessing and classification using a **Convolutional Neural Network (CNN)** on the CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3d1b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07ed138",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Load the CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbed3d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "print(\"Training data shape:\", train_images.shape)\n",
    "print(\"Testing data shape:\", test_images.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a18c4d5",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Visualize Raw Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98947248",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(train_images[i])\n",
    "    plt.title(class_names[train_labels[i][0]])\n",
    "    plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb27b0f",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Normalize Pixel Values (0‚Äì1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a23679e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042eeef8",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87af98c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5f8e09",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Visualize Augmented Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6f5b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "for i in range(9):\n",
    "    augmented_image = data_augmentation(tf.expand_dims(train_images[i], 0))\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(augmented_image[0])\n",
    "    plt.title(\"Augmented\")\n",
    "    plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573f4b76",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Define the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bd8619",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = models.Sequential([\n",
    "    data_augmentation,\n",
    "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a746236",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdc4185",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41f93cc",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Train the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f104e02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=15,\n",
    "    batch_size=64,\n",
    "    validation_data=(test_images, test_labels),\n",
    "    verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25cb24e",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dc99d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(\"Test accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c591260f",
   "metadata": {},
   "source": [
    "## üîü Visualize Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dea4833",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('CNN Training vs Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1c4a32",
   "metadata": {},
   "source": [
    "## üß© Predict and Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e7d7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = model.predict(test_images)\n",
    "plt.figure(figsize=(8,8))\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(test_images[i])\n",
    "    plt.title(f\"True: {class_names[test_labels[i][0]]}\\nPred: {class_names[np.argmax(predictions[i])]}\")\n",
    "    plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fda47ab",
   "metadata": {},
   "source": [
    "## ‚úÖ Summary: ANN vs CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7218ec4c",
   "metadata": {},
   "source": [
    "\n",
    "| Feature | ANN | CNN |\n",
    "|----------|-----|-----|\n",
    "| Input shape | Flattened (1D) | 2D spatial (H√óW√óC) |\n",
    "| Learns spatial patterns? | ‚ùå No | ‚úÖ Yes |\n",
    "| Parameters | High | Lower (shared weights) |\n",
    "| Use-case | Simple / tabular | Image, spatial data |\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
